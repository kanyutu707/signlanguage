{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96310ff7-a7ac-4d12-8340-ba1381fcf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch import optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c654017-8e23-4f6e-83cd-51a2b9e546b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "843df1dd-4693-4933-9414-9680a2c68db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.ImageFolder(root=\"./train/\", transform=transform)\n",
    "test_dataset=torchvision.datasets.ImageFolder(root=\"./test/\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e84064-9fe3-4a05-88b6-d9ef60486395",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader=torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f8ba29-9589-44be-a758-fcda24f0b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label=train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacc361e-49ee-4dfe-8097-5b26cb76e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d29e5fcc-2e80-4e78-92a4-254d3a33c3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccd76276-5000-411d-8c2c-381fc22c49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label=test_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeb93fd8-b23b-4903-81d6-bc17118c3ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50141955-ea0e-4e80-b7ec-378de5a6f0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722847a1-be99-4a14-ba3d-be2881676098",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['Church', 'Enough or Satisfied', 'Friend', 'Love', 'Me', 'Mosque', 'Seat', 'Temple', 'You']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d8f253-e513-4ccb-8c66-3df1dc98d62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5, 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 1)\n",
    "\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        flattened_size = 128 * 25 * 25  # = 80,000\n",
    "\n",
    "        self.fc1 = nn.Linear(flattened_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9879a366-54d2-4318-98f1-918dad6808de",
   "metadata": {},
   "outputs": [],
   "source": [
    "net=NeuralNet()\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "optimizer=optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "628a2fe8-493e-4207-af68-8ebd7ca58d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch 0 ....\n",
      "loss 2.197755\n",
      "Training epoch 1 ....\n",
      "loss 2.195818\n",
      "Training epoch 2 ....\n",
      "loss 2.192902\n",
      "Training epoch 3 ....\n",
      "loss 2.187945\n",
      "Training epoch 4 ....\n",
      "loss 2.173939\n",
      "Training epoch 5 ....\n",
      "loss 2.137274\n",
      "Training epoch 6 ....\n",
      "loss 2.076386\n",
      "Training epoch 7 ....\n",
      "loss 1.977762\n",
      "Training epoch 8 ....\n",
      "loss 1.875980\n",
      "Training epoch 9 ....\n",
      "loss 1.804643\n",
      "Training epoch 10 ....\n",
      "loss 1.723851\n",
      "Training epoch 11 ....\n",
      "loss 1.646193\n",
      "Training epoch 12 ....\n",
      "loss 1.559615\n",
      "Training epoch 13 ....\n",
      "loss 1.456020\n",
      "Training epoch 14 ....\n",
      "loss 1.354236\n",
      "Training epoch 15 ....\n",
      "loss 1.206631\n",
      "Training epoch 16 ....\n",
      "loss 1.033800\n",
      "Training epoch 17 ....\n",
      "loss 0.838562\n",
      "Training epoch 18 ....\n",
      "loss 0.618988\n",
      "Training epoch 19 ....\n",
      "loss 0.415275\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    print(f\"Training epoch {epoch} ....\")\n",
    "\n",
    "    running_loss=0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels=data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs=net(inputs)\n",
    "        loss=loss_function(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss+=loss.item()\n",
    "\n",
    "    print(f\"loss {running_loss / len(train_dataloader):4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4aaab3-6f9f-4aa9-929e-763b388c6fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edd696d2-4cef-4e41-8b23-262965407396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb49338c-7029-4813-a6c8-cdcb4024a6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 40.48%\n"
     ]
    }
   ],
   "source": [
    "correct=0\n",
    "total=0\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels=data\n",
    "        outputs=net(images)\n",
    "        _, predicted=torch.max(outputs, 1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicted==labels).sum().item()\n",
    "\n",
    "accuracy=100*correct/total\n",
    "\n",
    "print(f\"Accuracy {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e834c2ca-645e-4d24-b95c-0eec0daa51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20fcbf6a-8954-4e31-866c-600ffa19e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: You\n"
     ]
    }
   ],
   "source": [
    "def load_image(image_path):\n",
    "    image=Image.open(image_path)\n",
    "    image=transform(image)\n",
    "    image=image.unsqueeze(0)\n",
    "    return image\n",
    "image_paths=['C:\\\\Users\\\\kanyu\\\\projects\\\\signlanguage\\\\sol\\\\ImageID_0SFM7Q90.jpg']\n",
    "images=[load_image(img) for img in image_paths]\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for image in images:\n",
    "        output=net(image)\n",
    "        _, predicted=torch.max(output, 1)\n",
    "        print(f\"Prediction: {class_names[predicted.item()]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
